import torch
import torch.nn as nn
from PIL import Image
from torchvision import transforms

# RRDB block (simplified)
class RRDB(nn.Module):
    def __init__(self, channels=64):
        super().__init__()
        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)
        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)
        self.conv3 = nn.Conv2d(channels, channels, 3, padding=1)
        self.lrelu = nn.LeakyReLU(0.2, inplace=True)

    def forward(self, x):
        out = self.lrelu(self.conv1(x))
        out = self.lrelu(self.conv2(out))
        out = self.conv3(out)
        return x + out

class Generator(nn.Module):
    def __init__(self, num_rrdb=5):
        super().__init__()
        self.initial = nn.Conv2d(3, 64, 3, padding=1)
        self.rrdbs = nn.Sequential(*[RRDB(64) for _ in range(num_rrdb)])
        self.final = nn.Conv2d(64, 3, 3, padding=1)

    def forward(self, x):
        feat = self.initial(x)
        out = self.rrdbs(feat)
        return self.final(out)

def load_image(path):
    img = Image.open(path).convert('RGB')
    preprocess = transforms.ToTensor()
    return preprocess(img).unsqueeze(0)

def save_image(tensor, path):
    img = tensor.squeeze().clamp(0, 1)
    save = transforms.ToPILImage()(img)
    save.save(path)

if __name__ == '__main__':
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = Generator().to(device)
    # Assume model weights loaded 
    # model.load_state_dict(torch.load('generator.pth'))

    lr = load_image('/content/1b3b0a5e1ab348ccae48a148b7edb167.png').to(device)
    with torch.no_grad():
        sr = model(lr)
import os
os.makedirs("outputs", exist_ok=True)  

save_image(sr.cpu(), 'outputs/sr.png')
print("Super-resolved image saved to outputs/sr.png")

#--- NEXT PART ---

import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

IMAGE_PATH = '/content/1b3b0a5e1ab348ccae48a148b7edb167.png'
MODEL_HANDLE = "https://tfhub.dev/captain-pool/esrgan-tf2/1"

def load_img(path):
    img = Image.open(path).convert('RGB')
    img = img.resize((img.width // 4, img.height // 4), Image.BICUBIC)
    return np.array(img)

def preprocess(img):
    hr = img.astype(np.float32) / 255.0
    return tf.expand_dims(hr, 0)

def postprocess(sr):
    sr_img = tf.clip_by_value(sr[0], 0, 1)
    return (sr_img * 255).numpy().astype(np.uint8)

def visualize(lr, sr):
    plt.figure(figsize=(10,5))
    plt.subplot(1,2,1); plt.title('Original LR'); plt.imshow(lr)
    plt.subplot(1,2,2); plt.title('SR via TFâ€‘Hub ESRGAN'); plt.imshow(sr)
    plt.axis('off')
    plt.show()

def main():
    img = load_img(IMAGE_PATH)
    img_lr = img  # using the same image as LR for demo
    img_input = preprocess(img_lr)
    model = hub.load(MODEL_HANDLE)
    sr = model(img_input)
    sr_img = postprocess(sr)
    visualize(img_lr, sr_img)

if __name__ == '__main__':
    main()

#--- NEXT PART ---
import os
from PIL import Image
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms

# HR images
!wget -q https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip
!unzip -q DIV2K_train_HR.zip -d .

# LR images (bicubic downsampled x4)
!wget -q https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_bicubic_X4.zip
!unzip -q DIV2K_train_LR_bicubic_X4.zip -d .

class DIV2KDataset(Dataset):
    def __init__(self, root_lr, root_hr, patch_size=128):
        self.lr_files = sorted(os.listdir(root_lr))[:10]
        self.hr_files = sorted(os.listdir(root_hr))[:10]
        self.lr_root = root_lr
        self.hr_root = root_hr
        self.transform = transforms.ToTensor()
        self.patch = patch_size

    def __len__(self):
        return len(self.lr_files)

    def __getitem__(self, idx):
        lr = Image.open(os.path.join(self.lr_root, self.lr_files[idx])).convert('RGB')
        hr = Image.open(os.path.join(self.hr_root, self.hr_files[idx])).convert('RGB')

        # Random crop pair
        w, h = lr.size
        x = torch.randint(0, w - self.patch + 1, size=(1,)).item()
        y = torch.randint(0, h - self.patch + 1, size=(1,)).item()
        lr_c = lr.crop((x, y, x + self.patch, y + self.patch))
        hr_c = hr.crop((x*4, y*4, (x+self.patch)*4, (y+self.patch)*4))

        return self.transform(lr_c), self.transform(hr_c)

if __name__ == '__main__':
    dataset = DIV2KDataset('DIV2K_train_LR_bicubic/X4', 'DIV2K_train_HR')
    loader = DataLoader(dataset, batch_size=16, shuffle=True)
    for lr_batch, hr_batch in loader:
        print("LR batch shape:", lr_batch.shape, "HR batch shape:", hr_batch.shape)
        break
